{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c1721e7",
   "metadata": {},
   "source": [
    "# Support Vector Machine, SVM\n",
    "-  Support Vector Machine (SVM) is a supervised machine learning algorithm primarily used for classification tasks, although it can also be adapted for regression. The main idea of SVM is to find the optimal hyperplane that best separates the classes in the dataset. The hyperplane is chosen in such a way that the margin between the two classes is maximized, which means SVM tries to find the boundary that leaves the largest possible distance between different classes. This helps in improving the model's ability to generalize on unseen data.\n",
    "\n",
    "- SVM works well in high-dimensional spaces and is particularly effective in cases where the number of dimensions exceeds the number of data points. It also utilizes kernel functions to transform non-linearly separable data into a higher-dimensional space, making it easier to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6411cb07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'Count', 'Gender', 'Age', 'Under 30', 'Senior Citizen', 'Married', 'Dependents', 'Number of Dependents', 'City', 'Zip Code', 'Latitude', 'Longitude', 'Referred a Friend', 'Number of Referrals', 'Tenure in Months', 'Phone Service', 'Avg Monthly Long Distance Charges', 'Multiple Lines', 'Internet Service', 'Avg Monthly GB Download', 'Online Security', 'Online Backup', 'Device Protection Plan', 'Premium Tech Support', 'Streaming TV', 'Streaming Movies', 'Streaming Music', 'Unlimited Data', 'Paperless Billing', 'Monthly Charge', 'Total Charges', 'Total Refunds', 'Total Extra Data Charges', 'Total Long Distance Charges', 'Total Revenue', 'Satisfaction Score', 'Churn Value', 'Churn Score', 'CLTV', 'LoyaltyID', 'Partner', 'Tenure', 'Monthly Charges', 'Churn', 'Country_United States', 'State_California', 'Quarter_Q3', 'Offer_Offer A', 'Offer_Offer B', 'Offer_Offer C', 'Offer_Offer D', 'Offer_Offer E', 'Internet Type_Cable', 'Internet Type_DSL', 'Internet Type_Fiber Optic', 'Contract_Month-to-Month', 'Contract_One Year', 'Contract_Two Year', 'Payment Method_Bank Withdrawal', 'Payment Method_Credit Card', 'Payment Method_Mailed Check', 'Customer Status_Churned', 'Customer Status_Joined', 'Customer Status_Stayed', 'Churn Category_Attitude', 'Churn Category_Competitor', 'Churn Category_Dissatisfaction', 'Churn Category_Other', 'Churn Category_Price', 'Churn Reason_Attitude of service provider', 'Churn Reason_Attitude of support person', 'Churn Reason_Competitor had better devices', 'Churn Reason_Competitor made better offer', 'Churn Reason_Competitor offered higher download speeds', 'Churn Reason_Competitor offered more data', 'Churn Reason_Deceased', \"Churn Reason_Don't know\", 'Churn Reason_Extra data charges', 'Churn Reason_Lack of affordable download/upload speed', 'Churn Reason_Lack of self-service on Website', 'Churn Reason_Limited range of services', 'Churn Reason_Long distance charges', 'Churn Reason_Moved', 'Churn Reason_Network reliability', 'Churn Reason_Poor expertise of online support', 'Churn Reason_Poor expertise of phone support', 'Churn Reason_Price too high', 'Churn Reason_Product dissatisfaction', 'Churn Reason_Service dissatisfaction', 'Device Protection_No', 'Device Protection_No internet service', 'Device Protection_Yes', 'Tech Support_No', 'Tech Support_No internet service', 'Tech Support_Yes', 'Lat', 'Long', 'SeniorCitizen_Dependents', 'Tenure_Age_Ratio', 'AvgMonthlyGB_StreamServices', 'MonthlyCharge_TotalCharges_Ratio', 'AvgMonthlyGB_Tenure', 'Total_Services_Used', 'Streaming_Services_Count', 'Internet_Phone_Bundle', 'Tenure_in_Years', 'Digital_Payments', 'Traditional_Payments', 'Monthly_Charges_Scaled', 'Revenue_Cluster_Low', 'Revenue_Cluster_Medium', 'Revenue_Cluster_High', 'Refund_to_Charges_Ratio', 'Extra_Data_Usage_Cost_Proportion', 'Lifetime_Value_per_Month']\n",
      "Unnamed: 0                            int64\n",
      "Count                                 int64\n",
      "Gender                                int64\n",
      "Age                                   int64\n",
      "Under 30                              int64\n",
      "                                     ...   \n",
      "Revenue_Cluster_Medium                int64\n",
      "Revenue_Cluster_High                  int64\n",
      "Refund_to_Charges_Ratio             float64\n",
      "Extra_Data_Usage_Cost_Proportion    float64\n",
      "Lifetime_Value_per_Month            float64\n",
      "Length: 116, dtype: object\n",
      "['Churn Value', 'Churn Score', 'Churn', 'Customer Status_Churned', 'Churn Category_Attitude', 'Churn Category_Competitor', 'Churn Category_Dissatisfaction', 'Churn Category_Other', 'Churn Category_Price', 'Churn Reason_Attitude of service provider', 'Churn Reason_Attitude of support person', 'Churn Reason_Competitor had better devices', 'Churn Reason_Competitor made better offer', 'Churn Reason_Competitor offered higher download speeds', 'Churn Reason_Competitor offered more data', 'Churn Reason_Deceased', \"Churn Reason_Don't know\", 'Churn Reason_Extra data charges', 'Churn Reason_Lack of affordable download/upload speed', 'Churn Reason_Lack of self-service on Website', 'Churn Reason_Limited range of services', 'Churn Reason_Long distance charges', 'Churn Reason_Moved', 'Churn Reason_Network reliability', 'Churn Reason_Poor expertise of online support', 'Churn Reason_Poor expertise of phone support', 'Churn Reason_Price too high', 'Churn Reason_Product dissatisfaction', 'Churn Reason_Service dissatisfaction']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../2_data/telcocustomerchurn_featured.csv\")\n",
    "print(df.columns.tolist())\n",
    "print(df.dtypes)\n",
    "\n",
    "\n",
    "churn_columns = [col for col in df.columns if 'Churn' in col]\n",
    "print(churn_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e3da921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'Count', 'Gender', 'Age', 'Under 30', 'Senior Citizen', 'Married', 'Dependents', 'Number of Dependents', 'City', 'Zip Code', 'Latitude', 'Longitude', 'Referred a Friend', 'Number of Referrals', 'Tenure in Months', 'Phone Service', 'Avg Monthly Long Distance Charges', 'Multiple Lines', 'Internet Service', 'Avg Monthly GB Download', 'Online Security', 'Online Backup', 'Device Protection Plan', 'Premium Tech Support', 'Streaming TV', 'Streaming Movies', 'Streaming Music', 'Unlimited Data', 'Paperless Billing', 'Monthly Charge', 'Total Charges', 'Total Refunds', 'Total Extra Data Charges', 'Total Long Distance Charges', 'Total Revenue', 'Satisfaction Score', 'CLTV', 'LoyaltyID', 'Partner', 'Tenure', 'Monthly Charges', 'Churn', 'Country_United States', 'State_California', 'Quarter_Q3', 'Offer_Offer A', 'Offer_Offer B', 'Offer_Offer C', 'Offer_Offer D', 'Offer_Offer E', 'Internet Type_Cable', 'Internet Type_DSL', 'Internet Type_Fiber Optic', 'Contract_Month-to-Month', 'Contract_One Year', 'Contract_Two Year', 'Payment Method_Bank Withdrawal', 'Payment Method_Credit Card', 'Payment Method_Mailed Check', 'Customer Status_Joined', 'Customer Status_Stayed', 'Device Protection_No', 'Device Protection_No internet service', 'Device Protection_Yes', 'Tech Support_No', 'Tech Support_No internet service', 'Tech Support_Yes', 'Lat', 'Long', 'SeniorCitizen_Dependents', 'Tenure_Age_Ratio', 'AvgMonthlyGB_StreamServices', 'MonthlyCharge_TotalCharges_Ratio', 'AvgMonthlyGB_Tenure', 'Total_Services_Used', 'Streaming_Services_Count', 'Internet_Phone_Bundle', 'Tenure_in_Years', 'Digital_Payments', 'Traditional_Payments', 'Monthly_Charges_Scaled', 'Revenue_Cluster_Low', 'Revenue_Cluster_Medium', 'Revenue_Cluster_High', 'Refund_to_Charges_Ratio', 'Extra_Data_Usage_Cost_Proportion', 'Lifetime_Value_per_Month']\n",
      "StratifiedShuffleSplit(n_splits=5, random_state=7, test_size=0.2,\n",
      "            train_size=None)\n",
      "train: [4486 1855 3910 ... 4687  690 5658] test: [ 724  945 4710 ... 3730 1633 2496]\n",
      "train: [ 937 6833 3567 ... 4257 4716 5657] test: [6171  505 5903 ... 6911 2257 5571]\n",
      "train: [4793 2570 3406 ...  805 2103 1162] test: [  31 2128 2079 ... 2313 6356 5365]\n",
      "train: [6799  180 3061 ... 3155 2428  793] test: [3083 4441  980 ... 4552 2903 1479]\n",
      "train: [ 603 4034 6970 ... 1356 4927 1489] test: [5931 4868 2690 ... 3344 6206 5245]\n",
      "X shape: (7043, 83)\n",
      "X_train shape: (5634, 83)\n",
      "X_test shape: (1409, 83)\n",
      "y shape: (7043,)\n",
      "y_train shape: (5634,)\n",
      "y_test shape: (1409,)\n"
     ]
    }
   ],
   "source": [
    "# Drop all columns containing \"Churn\" in their name except the \"Churn\" column\n",
    "churn_columns_to_drop = [col for col in churn_columns if col != 'Churn']\n",
    "df = df.drop(columns=churn_columns_to_drop)\n",
    "\n",
    "# Display the remaining columns\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Define the features and target variable\n",
    "X = df.drop(columns=['Churn', 'Unnamed: 0', 'Customer Status_Joined', 'Customer Status_Stayed', 'LoyaltyID'])\n",
    "y = df['Churn']\n",
    "\n",
    "# StratifiedShuffleSplit \n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=7)\n",
    "print(sss)\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"train:\", train_index, \"test:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Save the train and test splits to CSV files\n",
    "X_train.to_csv(\"../2_data/X_train.csv\", index=False)\n",
    "X_test.to_csv(\"../2_data/X_test.csv\", index=False)\n",
    "y_train.to_csv(\"../2_data/y_train.csv\", index=False)\n",
    "y_test.to_csv(\"../2_data/y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2371cdcb",
   "metadata": {},
   "source": [
    "# How is SVM Used in Our Project?\n",
    "- In the context of customer churn prediction, SVM can be used to classify whether a customer is likely to churn or stay. The goal of our project is to predict customer behavior based on a variety of customer-related features. By training an SVM classifier on historical data (which contains information about customer behaviors and whether they churned), the model will learn patterns that help distinguish churned customers from non-churned customers.\n",
    "\n",
    "For example:\n",
    "\n",
    "- Feature Selection: We provide SVM with features such as tenure, monthly charges, service type, etc. These features help SVM understand which factors are most influential in determining whether a customer will churn.\n",
    "- Kernel Trick: If the relationship between features and churn is not linearly separable, we can use kernel functions (e.g., radial basis function or polynomial kernel) to map these features to a higher-dimensional space where a linear boundary may become more apparent.\n",
    "- Classification: The SVM model is then used to create a decision boundary that separates customers who are likely to churn from those who are not. Once trained, this decision boundary can be used to predict the likelihood of churn for new or unseen customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081c0e0a",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "- This function clean_features(X) is used to clean the dataset. You remove columns like 'Unnamed: 0', 'Customer Status_Stayed', and 'Customer Status_Joined' because they do not contribute useful information for prediction. After that, you also remove columns with very low variance, as they provide very little distinction between data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d098ed9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def clean_features(X):\n",
    "\n",
    "    cols_to_remove = ['Unnamed: 0', 'Customer Status_Stayed', 'Customer Status_Joined']\n",
    "    for col in cols_to_remove:\n",
    "        if col in X.columns:\n",
    "            X = X.drop(columns=[col])\n",
    "    \n",
    "  \n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "    low_variance_features = [\n",
    "        col for col in numeric_cols if X[col].var() < 0.01\n",
    "    ]\n",
    "    X = X.drop(columns=low_variance_features)\n",
    "    \n",
    "    return X, low_variance_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4e8f26",
   "metadata": {},
   "source": [
    "### Feature Standardization\n",
    "- You used StandardScaler to standardize the features. This means scaling all the feature values to the same range, which is particularly important for SVM because it is sensitive to the scale of input features. The fit_transform() function is used for fitting and transforming the training set, while transform() is used to apply the transformation on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b32efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c3534d",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning and Model Training\n",
    "- Here, you import SVC from sklearn.svm and define a parameter grid (param_grid) to try different combinations of hyperparameters. These hyperparameters include C (the penalty parameter), gamma (the kernel parameter), and kernel (the type of kernel function). You then use GridSearchCV to find the best combination of hyperparameters through cross-validation with 5 folds. After training, the best estimator is used to make predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "310e5e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV  \n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1, 10],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "svm_classifier = SVC(class_weight='balanced', random_state=42)\n",
    "grid_search = GridSearchCV(svm_classifier, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "# use the best estimator\n",
    "y_pred = grid_search.best_estimator_.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bd3eb2",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "## Accuracy\n",
    "- In this code snippet, the accuracy of the Support Vector Machine (SVM) model on the test dataset is calculated. The accuracy metric indicates the proportion of correctly classified instances among the total instances. In this case, the accuracy score is 0.78, meaning that the model is able to correctly classify 78% of the test samples.\n",
    "\n",
    "- While an accuracy of 78% may seem acceptable, it's essential to keep in mind that for a customer churn prediction problem, we usually deal with imbalanced data. Relying solely on accuracy might not give a complete picture of the model's performance, as the model might be biased towards the majority class (e.g., predicting that most customers will not churn). It's crucial to evaluate other metrics like precision, recall, F1-score, and ROC-AUC to gain more insights into the model's effectiveness, especially in identifying the minority (churned) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60165882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfe8913",
   "metadata": {},
   "source": [
    "## Precision and Recall\n",
    "- We calculate two evaluation metrics: precision and recall for the Support Vector Machine (SVM) model. These metrics provide insights into how well the model is predicting the churned customers, which is important for customer churn prediction projects.\n",
    "\n",
    "- Precision (0.73): Precision represents the proportion of correctly predicted churned customers (true positives) out of all customers predicted to churn (true positives + false positives). In this case, precision is 0.73, which means that 73% of the customers that the model predicted to churn actually did churn. This metric tells us how precise our model is in identifying actual churned customers.\n",
    "\n",
    "- Recall (0.30): Recall represents the proportion of actual churned customers (true positives) that the model was able to identify out of all churned customers (true positives + false negatives). In this case, recall is 0.30, which means that the model is able to identify only 30% of the actual churned customers. This indicates that the model has a relatively low sensitivity and may be missing many churned customers.\n",
    "\n",
    "- In customer churn prediction projects, having a high recall is usually crucial to ensure that as many churned customers as possible are correctly identified so that retention strategies can be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e0fd228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.88\n",
      "Recall: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Compute Recall and Precision\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)  # label 1 as churn\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c81e213",
   "metadata": {},
   "source": [
    "## F1-Score\n",
    "- In this code snippet, the F1-Score is calculated for the predictions made by the SVM classifier.\n",
    "\n",
    "- F1-Score (0.43): The F1-Score is the harmonic mean of precision and recall, providing a single metric that balances both. It is particularly useful when dealing with imbalanced datasets, as it accounts for both false positives and false negatives. An F1-Score of 0.43 means that the model's performance in terms of precision and recall is relatively low. The low F1-Score indicates that although the model has some ability to correctly predict churned customers, there is still significant room for improvement, especially regarding balancing the identification and accuracy of churned customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9869f54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# compute F1-Score\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "print(f'F1-Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987ddd07",
   "metadata": {},
   "source": [
    "## ROC-AUC Score\n",
    "-  the ROC-AUC Score is calculated to evaluate the performance of the SVM classifier.\n",
    "\n",
    "- ROC-AUC Score (0.63): The ROC-AUC Score (Receiver Operating Characteristic - Area Under the Curve) measures the model's ability to distinguish between positive and negative classes. A score of 1.0 represents perfect classification, while 0.5 represents random guessing. In this example, the ROC-AUC score is 0.63, which is only slightly better than random, indicating that the model has limited capability in distinguishing between churned and non-churned customers. The model requires further tuning or improvement to achieve better classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a2c64a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC Score: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(f'ROC-AUC Score: {roc_auc:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690602f1",
   "metadata": {},
   "source": [
    "# Summary\n",
    "- The performance of the SVM model in customer churn prediction is not satisfactory, particularly in terms of recall and distinguishing capability (ROC-AUC). The low recall and F1-score indicate that the model has missed a significant number of churned customers, which could negatively impact business decisions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
