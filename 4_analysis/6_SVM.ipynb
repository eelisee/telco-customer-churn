{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c1721e7",
   "metadata": {},
   "source": [
    "# Support Vector Machine, SVM\n",
    "-  Support Vector Machine (SVM) is a supervised machine learning algorithm primarily used for classification tasks, although it can also be adapted for regression. The main idea of SVM is to find the optimal hyperplane that best separates the classes in the dataset. The hyperplane is chosen in such a way that the margin between the two classes is maximized, which means SVM tries to find the boundary that leaves the largest possible distance between different classes. This helps in improving the model's ability to generalize on unseen data.\n",
    "\n",
    "- SVM works well in high-dimensional spaces and is particularly effective in cases where the number of dimensions exceeds the number of data points. It also utilizes kernel functions to transform non-linearly separable data into a higher-dimensional space, making it easier to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6411cb07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e3da921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load the pre-split dataset\n",
    "\n",
    "# Read the training and testing datasets from CSV files\n",
    "X_train = pd.read_csv(\"../2_data/X_train.csv\")\n",
    "X_test = pd.read_csv(\"../2_data/X_test.csv\")\n",
    "y_train = pd.read_csv(\"../2_data/y_train.csv\")\n",
    "y_test = pd.read_csv(\"../2_data/y_test.csv\")\n",
    "\n",
    "# Ensure the target variable has the correct shape (1D array)\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2371cdcb",
   "metadata": {},
   "source": [
    "# How is SVM Used in Our Project?\n",
    "- In the context of customer churn prediction, SVM can be used to classify whether a customer is likely to churn or stay. The goal of our project is to predict customer behavior based on a variety of customer-related features. By training an SVM classifier on historical data (which contains information about customer behaviors and whether they churned), the model will learn patterns that help distinguish churned customers from non-churned customers.\n",
    "\n",
    "For example:\n",
    "\n",
    "- Feature Selection: We provide SVM with features such as tenure, monthly charges, service type, etc. These features help SVM understand which factors are most influential in determining whether a customer will churn.\n",
    "- Kernel Trick: If the relationship between features and churn is not linearly separable, we can use kernel functions (e.g., radial basis function or polynomial kernel) to map these features to a higher-dimensional space where a linear boundary may become more apparent.\n",
    "- Classification: The SVM model is then used to create a decision boundary that separates customers who are likely to churn from those who are not. Once trained, this decision boundary can be used to predict the likelihood of churn for new or unseen customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081c0e0a",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "- This function clean_features(X) is used to clean the dataset. You remove columns like 'Unnamed: 0', 'Customer Status_Stayed', and 'Customer Status_Joined' because they do not contribute useful information for prediction. After that, you also remove columns with very low variance, as they provide very little distinction between data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d098ed9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def clean_features(X):\n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "    low_variance_features = [\n",
    "        col for col in numeric_cols if X[col].var() < 0.01\n",
    "    ]\n",
    "    X = X.drop(columns=low_variance_features)\n",
    "    \n",
    "    return X, low_variance_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4e8f26",
   "metadata": {},
   "source": [
    "### Feature Standardization\n",
    "- We use StandardScaler to standardize the features. This means scaling all the feature values to the same range, which is particularly important for SVM because it is sensitive to the scale of input features. The fit_transform() function is used for fitting and transforming the training set, while transform() is used to apply the transformation on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1b32efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c3534d",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning and Model Training\n",
    "- Here, we import SVC from sklearn.svm and define a parameter grid (param_grid) to try different combinations of hyperparameters. These hyperparameters include C (the penalty parameter), gamma (the kernel parameter), and kernel (the type of kernel function). We then use GridSearchCV to find the best combination of hyperparameters through cross-validation with 5 folds. After training, the best estimator is used to make predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "310e5e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV  \n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1, 10],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "svm_classifier = SVC(class_weight='balanced', random_state=42)\n",
    "grid_search = GridSearchCV(svm_classifier, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "# use the best estimator\n",
    "y_pred = grid_search.best_estimator_.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bd3eb2",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "## Accuracy\n",
    "- In this code snippet, the accuracy of the Support Vector Machine (SVM) model on the test dataset is calculated. The accuracy metric indicates the proportion of correctly classified instances among the total instances. In this case, the accuracy score is 0.96, meaning that the model is able to correctly classify 96% of the test samples.\n",
    "\n",
    "- While an accuracy of 96% may seem acceptable, it's essential to keep in mind that for a customer churn prediction problem, we usually deal with imbalanced data. Relying solely on accuracy might not give a complete picture of the model's performance, as the model might be biased towards the majority class (e.g., predicting that most customers will not churn). It's crucial to evaluate other metrics like precision, recall, F1-score, and ROC-AUC to gain more insights into the model's effectiveness, especially in identifying the minority (churned) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60165882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfe8913",
   "metadata": {},
   "source": [
    "## Precision and Recall\n",
    "- We calculate two evaluation metrics: precision and recall for the Support Vector Machine (SVM) model. These metrics provide insights into how well the model is predicting the churned customers, which is important for customer churn prediction projects.\n",
    "\n",
    "- Precision (0.88): Precision represents the proportion of correctly predicted churned customers (true positives) out of all customers predicted to churn (true positives + false positives). In this case, precision is 0.88, which means that 73% of the customers that the model predicted to churn actually did churn. This metric tells us how precise our model is in identifying actual churned customers.\n",
    "\n",
    "- Recall (0.96): Recall represents the proportion of actual churned customers (true positives) that the model was able to identify out of all churned customers (true positives + false negatives). In this case, recall is 0.96, which means that the model is able to identify only 96% of the actual churned customers. This indicates that the model has a relatively high sensitivity and may be missing only a few churned customers.\n",
    "\n",
    "- In customer churn prediction projects, having a high recall is usually crucial to ensure that as many churned customers as possible are correctly identified so that retention strategies can be applied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c81e213",
   "metadata": {},
   "source": [
    "## F1-Score\n",
    "- In this code snippet, the F1-Score is calculated for the predictions made by the SVM classifier.\n",
    "\n",
    "- F1-Score (0.92): The F1-Score is the harmonic mean of precision and recall, providing a single metric that balances both. It is particularly useful when dealing with imbalanced datasets, as it accounts for both false positives and false negatives. An F1-Score of 0.92 means that the model's performance in terms of precision and recall is relatively low. The low F1-Score indicates that although the model has some ability to correctly predict churned customers, there is still significant room for improvement, especially regarding balancing the identification and accuracy of churned customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9869f54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# compute F1-Score\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "print(f'F1-Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987ddd07",
   "metadata": {},
   "source": [
    "## ROC-AUC Score\n",
    "-  the ROC-AUC Score is calculated to evaluate the performance of the SVM classifier.\n",
    "\n",
    "- ROC-AUC Score (0.96): The ROC-AUC Score (Receiver Operating Characteristic - Area Under the Curve) measures the model's ability to distinguish between positive and negative classes. A score of 1.0 represents perfect classification, while 0.5 represents random guessing. In this example, the ROC-AUC score is 0.96, which is way better than random, indicating that the model has high capability in distinguishing between churned and non-churned customers. The model requires further tuning or improvement to achieve better classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a2c64a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC Score: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(f'ROC-AUC Score: {roc_auc:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e0fd228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n",
      "Precision: 0.88\n",
      "Recall: 0.96\n",
      "F1 Score: 0.92\n",
      "ROC AUC: 0.96\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute Evaluation Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)  # label 1 as churn\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print(f'ROC AUC: {roc_auc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00e59d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_metrics = {\n",
    "    \"accuracy\": accuracy,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "    \"f1\": f1,\n",
    "    \"roc_auc\": roc_auc\n",
    "}\n",
    "evaluation_df = pd.DataFrame([evaluation_metrics])\n",
    "evaluation_df.to_csv(\"../2_data/evaluation_metrics/SVM.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690602f1",
   "metadata": {},
   "source": [
    "# Summary\n",
    "- The performance of the SVM model in customer churn prediction is not satisfactory, particularly in terms of recall and distinguishing capability (ROC-AUC). The low recall and F1-score indicate that the model has missed a significant number of churned customers, which could negatively impact business decisions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
