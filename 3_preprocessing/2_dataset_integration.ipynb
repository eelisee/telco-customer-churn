{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Dataset Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Pipeline Overview\n",
    "\n",
    "This preprocessing pipeline outlines the steps necessary to prepare the Telco Customer Churn dataset for our modeling. Each step is designed to address specific aspects of data quality, transformation, and feature creation. We will cover each step in a separate jupyter notebook file.\n",
    "\n",
    "**Step 1: Data Loading**: Loading the datasets into the workspace, ensuring all necessary files are correctly imported for analysis. This includes the Kaggle dataset and the IBM datasets.\n",
    "\n",
    "**Step 2: Dataset Integration**: Combining relevant datasets into a single, unified dataset that will serve as the foundation for subsequent analysis.\n",
    "\n",
    "**Step 3: Data Exploration**: Perform initial exploratory data analysis (EDA) to understand the dataset's structure and characteristics, visualizing key features to gain insights into the data.\n",
    "\n",
    "**Step 4: Handling Missing Values**: Identifying and addressing missing values in the dataset to ensure data integrity. This step ensures no significant gaps hinder the analysis.\n",
    "\n",
    "**Step 5: Data Type Conversion**: Converting data columns to appropriate data types to optimize memory usage and prepare for feature engineering. Ensure consistency across all columns.\n",
    "\n",
    "**Step 6: Feature Engineering**: Creating new features from the existing data to enhance model performance and capture additional insights. This includes transformations and derived features.\n",
    "\n",
    "**Step 7: Outlier Detection**: Identifying and addressing outliers in the dataset to ensure they do not negatively impact the analysis or models.\n",
    "\n",
    "**Step 8: Dataset Splitting**: Splitting the dataset into training and testing subsets to prepare for model development and evaluation. This step ensures reproducibility and robust performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "df_customerc = pd.read_csv('../2_data/Telco_customer_churn_customerc.csv')\n",
    "df_telcocustomerc = pd.read_csv('../2_data/Telco_customer_churn_telcocustomerc.csv')\n",
    "df_demographics = pd.read_csv('../2_data/Telco_customer_churn_demographics.csv')\n",
    "df_location = pd.read_csv('../2_data/Telco_customer_churn_location.csv')\n",
    "df_population = pd.read_csv('../2_data/Telco_customer_churn_population.csv')\n",
    "df_services = pd.read_csv('../2_data/Telco_customer_churn_services.csv')\n",
    "df_status = pd.read_csv('../2_data/Telco_customer_churn_status.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section, we will compare the columns of the `customerc` and `telcocustomerc` datasets with the other five topics: demographics, location, population, services, and status. This comparison will help us identify any unique or overlapping columns, ensuring that we capture all relevant information in our combined dataset.\n",
    "\n",
    "After thoroughly analyzing all relevant datasets, we aim to create a comprehensive combined dataset. This new dataset will integrate information from multiple sources, enriching the data with additional columns and insights. By merging these resources, we can leverage a more detailed and holistic view of customer information, which will enhance our analysis and modeling efforts. This combined dataset will serve as a robust foundation for further exploration and predictive modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Comparing the Customer Churn Data with the other Datasets\n",
    "\n",
    "The key difference between the `CustomerChurn.xlsx` dataset and the other existing CSV files is that `CustomerChurn.xlsx` provides a comprehensive view of customer information, including demographics, account details, services subscribed, and churn status, all in a single file. In contrast, the other CSV files are more specialized, each focusing on specific aspects such as demographics, location, population, services, and customer status. We furthermore have looked at the columns of the `df_customerc` and compared them with the already existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns not in df_customerc:\n",
      "Index(['Age', 'Avg Monthly GB Download', 'Avg Monthly Long Distance Charges',\n",
      "       'CLTV', 'Churn Category', 'Churn Label', 'Churn Reason', 'Churn Score',\n",
      "       'Churn Value', 'City', 'Count', 'Country', 'Customer Status',\n",
      "       'Device Protection Plan', 'Gender', 'ID', 'Internet Type', 'Lat Long',\n",
      "       'Latitude', 'Location ID', 'Longitude', 'Married', 'Monthly Charge',\n",
      "       'Number of Dependents', 'Number of Referrals', 'Offer', 'Population',\n",
      "       'Premium Tech Support', 'Quarter', 'Referred a Friend',\n",
      "       'Satisfaction Score', 'Service ID', 'State', 'Status ID',\n",
      "       'Streaming Music', 'Tenure in Months', 'Total Extra Data Charges',\n",
      "       'Total Long Distance Charges', 'Total Refunds', 'Total Revenue',\n",
      "       'Under 30', 'Unlimited Data', 'Zip Code'],\n",
      "      dtype='object')\n",
      "\n",
      "Columns not in all the data of the combined dataset of demographics, location, populaton, services and status:\n",
      "Index(['Churn', 'Device Protection', 'LoyaltyID', 'Monthly Charges', 'Partner',\n",
      "       'Tech Support', 'Tenure'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Combine all column names from the datasets\n",
    "columns_demographics = df_demographics.columns\n",
    "columns_location = df_location.columns\n",
    "columns_population = df_population.columns\n",
    "columns_services = df_services.columns\n",
    "columns_status = df_status.columns\n",
    "\n",
    "# Combine all unique column names\n",
    "all_columns = columns_demographics.union(columns_location).union(columns_population).union(columns_services).union(columns_status)\n",
    "\n",
    "columns_customerc = df_customerc.columns\n",
    "\n",
    "# Compare columns\n",
    "columns_not_in_customerc = all_columns.difference(columns_customerc) # returns a set of columns that are in all_columns but not in df_customerc\n",
    "columns_not_in_all = columns_customerc.difference(all_columns) # returns a set of columns that are in df_customerc but not in all_columns\n",
    "\n",
    "# Print results\n",
    "print(\"\\nColumns not in df_customerc:\")\n",
    "print(columns_not_in_customerc)\n",
    "print(\"\\nColumns not in all the data of the combined dataset of demographics, location, populaton, services and status:\")\n",
    "print(columns_not_in_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Missing Columns in `df_customerc`\n",
    "\n",
    "Adding `df_customerc` to the combined dataset is useful because:\n",
    "\n",
    "1. **Comprehensive Information**: It includes crucial columns like `Churn`, `LoyaltyID`, and `Tenure` that are not in the combined dataset.\n",
    "2. **Enhanced Churn Analysis**: The `Churn` column provides a direct indicator of churn, essential for predictive modeling.\n",
    "3. **Customer Loyalty Insights**: The `LoyaltyID` column helps analyze customer loyalty patterns.\n",
    "4. **Tenure Information**: The `Tenure` column provides tenure duration, important for retention analysis.\n",
    "5. **Rich Demographic and Geographical Data**: The combined dataset's demographic and geographical data enhance customer behavior analysis.\n",
    "\n",
    "Integrating `df_customerc` with the combined dataset provides a more comprehensive understanding of customer behavior, churn patterns, and loyalty, enabling accurate predictive modeling and data-driven decision-making.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Comparing the Telco Customer Churn Data with the Other Datasets\n",
    "\n",
    "The key difference between the `Telco_customer_churn.xlsx` dataset and the other existing CSV files is that `Telco_customer_churn.xlsx` provides a comprehensive view of customer information, including demographics, account details, services subscribed, and churn status, all in a single file. In contrast, the other CSV files are more specialized, each focusing on specific aspects such as demographics, location, population, services, and customer status. We furthermore have looked at the columns of the `df_telcocustomerc` and compared them with the already existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns that are in the combined dataset of demographics, location, populaton, services and status but not in df_telcocustomerc:\n",
      "Index(['Age', 'Avg Monthly GB Download', 'Avg Monthly Long Distance Charges',\n",
      "       'Churn Category', 'Customer ID', 'Customer Status',\n",
      "       'Device Protection Plan', 'ID', 'Internet Type', 'Location ID',\n",
      "       'Married', 'Monthly Charge', 'Number of Dependents',\n",
      "       'Number of Referrals', 'Offer', 'Population', 'Premium Tech Support',\n",
      "       'Quarter', 'Referred a Friend', 'Satisfaction Score', 'Service ID',\n",
      "       'Status ID', 'Streaming Music', 'Tenure in Months',\n",
      "       'Total Extra Data Charges', 'Total Long Distance Charges',\n",
      "       'Total Refunds', 'Total Revenue', 'Under 30', 'Unlimited Data'],\n",
      "      dtype='object')\n",
      "\n",
      "Columns that are in the df_telcocustomerc, but not in all the data of the combined dataset of demographics, location, populaton, services and status:\n",
      "Index(['CustomerID', 'Device Protection', 'Monthly Charges', 'Partner',\n",
      "       'Tech Support', 'Tenure Months'],\n",
      "      dtype='object')\n",
      "\n",
      "Columns that are in df_customerc but not in df_telcocustomerc:\n",
      "Index(['Churn', 'Customer ID', 'LoyaltyID', 'Tenure'], dtype='object')\n",
      "\n",
      "Columns that are in df_telcocustomerc but not in df_customerc:\n",
      "Index(['CLTV', 'Churn Label', 'Churn Reason', 'Churn Score', 'Churn Value',\n",
      "       'City', 'Count', 'Country', 'CustomerID', 'Gender', 'Lat Long',\n",
      "       'Latitude', 'Longitude', 'State', 'Tenure Months', 'Zip Code'],\n",
      "      dtype='object')\n",
      "\n",
      "Columns that are neither in df_telcocustomerc nor in all the data of the combined dataset of demographics, location, populaton, services and status nor in df_customerc:\n",
      "Index(['CustomerID', 'Tenure Months'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "columns_telcocustomerc = df_telcocustomerc.columns\n",
    "\n",
    "# Compare columns\n",
    "columns_not_in_telcocustomerc_all = all_columns.difference(columns_telcocustomerc) # returns a set of columns that are in all_columns but not in df_telcocustomerc\n",
    "columns_not_in_all_telcocustomerc = columns_telcocustomerc.difference(all_columns) # returns a set of columns that are in df_customerc but not in all_columns\n",
    "columns_not_in_telcocustomerc_customerc = columns_customerc.difference(columns_telcocustomerc) # returns a set of columns that are in df_customerc but not in df_telcocustomerc\n",
    "columns_not_in_customerc_telcocustomerc = columns_telcocustomerc.difference(columns_customerc) # returns a set of columns that are in df_telcocustomerc but not in df_customerc\n",
    "columns_in_telcocustomerc_not_in_all_nor_customerc = columns_telcocustomerc.difference(all_columns).difference(columns_customerc) # returns a set of columns that are in df_telcocustomerc but not in all_columns nor in df_customerc\n",
    "\n",
    "# Print results\n",
    "print(\"\\nColumns that are in the combined dataset of demographics, location, populaton, services and status but not in df_telcocustomerc:\")\n",
    "print(columns_not_in_telcocustomerc_all)\n",
    "print(\"\\nColumns that are in the df_telcocustomerc, but not in all the data of the combined dataset of demographics, location, populaton, services and status:\")\n",
    "print(columns_not_in_all_telcocustomerc)\n",
    "print(\"\\nColumns that are in df_customerc but not in df_telcocustomerc:\")\n",
    "print(columns_not_in_telcocustomerc_customerc)\n",
    "print(\"\\nColumns that are in df_telcocustomerc but not in df_customerc:\")\n",
    "print(columns_not_in_customerc_telcocustomerc)\n",
    "print(\"\\nColumns that are neither in df_telcocustomerc nor in all the data of the combined dataset of demographics, location, populaton, services and status nor in df_customerc:\")\n",
    "print(columns_in_telcocustomerc_not_in_all_nor_customerc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Missing Columns in `df_telcocustomerc`\n",
    "\n",
    "Based on the evaluation of the columns, here are the conclusions regarding whether to include the `df_telcocustomerc` dataset:\n",
    "\n",
    "**Columns neither in `df_telcocustomerc` nor in the Combined Dataset nor in `df_customerc`**: None.\n",
    "\n",
    "The `df_telcocustomerc` dataset does not contain any additional unique columns that are not already present in the combined dataset or `df_customerc`. Therefore, there is no additional information provided by the `df_telcocustomerc` dataset that would justify its inclusion in further analysis.\n",
    "\n",
    "Given that the `df_telcocustomerc` dataset does not offer any unique or additional information beyond what is already available in the combined dataset and `df_customerc`, we will not include the `df_telcocustomerc` dataset in further analysis. This approach ensures that our analysis remains streamlined and avoids redundancy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Creating combined Dataset\n",
    "\n",
    "Based on the analysis, we decided to create the combined dataset using the five datasets (demographics, location, population, services, and status) along with the `customerc` dataset. The `telcocustomerc` dataset was excluded because it did not provide any additional unique information that would enhance the combined dataset. By integrating the selected datasets, we ensure a comprehensive and enriched dataset that captures all relevant aspects of customer information, enabling more accurate and insightful analysis and predictive modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Customer ID' is available as a column name in dataframe 1\n",
      "'Customer ID' is available as a column name in dataframe 2\n",
      "'Customer ID' is NOT available as a column name in dataframe 3\n",
      "'Customer ID' is available as a column name in dataframe 4\n",
      "'Customer ID' is available as a column name in dataframe 5\n",
      "'Customer ID' is available as a column name in dataframe 6\n"
     ]
    }
   ],
   "source": [
    "# Check if 'Customer ID' is a unique column name in all datasets\n",
    "\n",
    "# List of dataframes to check\n",
    "dataframes = [df_demographics, df_location, df_population, df_services, df_status, df_customerc]\n",
    "\n",
    "# Check for 'Customer ID' column in each dataframe\n",
    "for i, df in enumerate(dataframes):\n",
    "    if 'Customer ID' in df.columns:\n",
    "        print(f\"'Customer ID' is available as a column name in dataframe {i+1}\")\n",
    "    else:\n",
    "        print(f\"'Customer ID' is NOT available as a column name in dataframe {i+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All customer IDs are unique and exist in all dataframes.\n"
     ]
    }
   ],
   "source": [
    "# Check for unique customer IDs in each dataframe\n",
    "unique_ids_demographics = df_demographics['Customer ID'].unique()\n",
    "unique_ids_location = df_location['Customer ID'].unique()\n",
    "unique_ids_services = df_services['Customer ID'].unique()\n",
    "unique_ids_status = df_status['Customer ID'].unique()\n",
    "unique_ids_customerc = df_customerc['Customer ID'].unique()\n",
    "\n",
    "# Verify that each customer ID in df_demographics exists in other dataframes\n",
    "common_ids = set(unique_ids_demographics).intersection(\n",
    "    set(unique_ids_location),\n",
    "    set(unique_ids_services),\n",
    "    set(unique_ids_status),\n",
    "    set(unique_ids_customerc)\n",
    ")\n",
    "\n",
    "# Check if the number of common IDs matches the number of unique IDs in all dataframes\n",
    "if len(common_ids) == len(unique_ids_demographics) == len(unique_ids_location) == len(unique_ids_services) == len(unique_ids_status) == len(unique_ids_customerc):\n",
    "    print(\"All customer IDs are unique and exist in all dataframes.\")\n",
    "else:\n",
    "    print(\"There are customer IDs that do not match between the dataframes.\")\n",
    "\n",
    "# print the IDs that do not match\n",
    "missing_in_location = set(unique_ids_demographics) - set(unique_ids_location)\n",
    "missing_in_services = set(unique_ids_demographics) - set(unique_ids_services)\n",
    "missing_in_status = set(unique_ids_demographics) - set(unique_ids_status)\n",
    "missing_in_customerc = set(unique_ids_demographics) - set(unique_ids_customerc)\n",
    "\n",
    "if missing_in_location:\n",
    "    print(f\"Customer IDs in df_demographics but not in df_location: {missing_in_location}\")\n",
    "if missing_in_services:\n",
    "    print(f\"Customer IDs in df_demographics but not in df_services: {missing_in_services}\")\n",
    "if missing_in_status:\n",
    "    print(f\"Customer IDs in df_demographics but not in df_status: {missing_in_status}\")\n",
    "if missing_in_customerc:\n",
    "    print(f\"Customer IDs in df_demographics but not in df_customerc: {missing_in_customerc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Tests for Creating Combined Dataset\n",
    "\n",
    "To ensure the feasibility of creating a combined dataset from the `df_demographics`, `df_location`, `df_services`, `df_status`, and `df_customerc` dataframes, we conducted several tests to verify the uniqueness and consistency of customer IDs across these dataframes.\n",
    "\n",
    "**Comparing Column Names**: We verified that the `Customer ID` column exists in all the dataframes (`df_demographics`, `df_location`, `df_services`, `df_status`, and `df_customerc`). In every dataset, the `Customer ID` column existed, except in the `df_population` dataframe.\n",
    "\n",
    "\n",
    "**Checking for Unique Customer IDs**: We confirmed that each `Customer ID` is unique within each dataframe.\n",
    "\n",
    "\n",
    "\n",
    "Based on the tests conducted, we concluded that it is feasible to create a combined dataset from the `df_demographics`, `df_location`, `df_services`, `df_status`, and `df_customerc` dataframes. All customer IDs are unique and exist in all dataframes, ensuring that we can accurately merge the data without any loss of information. \n",
    "We will leave out the population dataset due to the missing `Customer ID`, which prevents us from uniquely merging the entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0_demographics Customer ID  Count_demographics  Gender  Age  \\\n",
      "0                     4006  0002-ORFBO                   1  Female   37   \n",
      "1                     4788  0003-MKNFE                   1    Male   46   \n",
      "2                     1901  0004-TLHLJ                   1    Male   50   \n",
      "3                      395  0011-IGKFF                   1    Male   78   \n",
      "4                      368  0013-EXCHZ                   1  Female   75   \n",
      "\n",
      "  Under 30 Senior Citizen Married Dependents  Number of Dependents  ...  \\\n",
      "0       No             No     Yes         No                     0  ...   \n",
      "1       No             No      No         No                     0  ...   \n",
      "2       No             No      No         No                     0  ...   \n",
      "3       No            Yes     Yes         No                     0  ...   \n",
      "4       No            Yes     Yes         No                     0  ...   \n",
      "\n",
      "   Device Protection Tech Support  Streaming TV_customerc  \\\n",
      "0                 No          Yes                     Yes   \n",
      "1                 No           No                      No   \n",
      "2                Yes           No                      No   \n",
      "3                Yes           No                     Yes   \n",
      "4                 No          Yes                     Yes   \n",
      "\n",
      "  Streaming Movies_customerc Contract_customerc Paperless Billing_customerc  \\\n",
      "0                         No           One year                         Yes   \n",
      "1                        Yes     Month-to-month                          No   \n",
      "2                         No     Month-to-month                         Yes   \n",
      "3                        Yes     Month-to-month                         Yes   \n",
      "4                         No     Month-to-month                         Yes   \n",
      "\n",
      "   Payment Method_customerc Monthly Charges  Total Charges_customerc  Churn  \n",
      "0              Mailed check            65.6                    593.3     No  \n",
      "1              Mailed check            59.9                    542.4     No  \n",
      "2          Electronic check            73.9                   280.85    Yes  \n",
      "3          Electronic check            98.0                  1237.85    Yes  \n",
      "4              Mailed check            83.9                    267.4    Yes  \n",
      "\n",
      "[5 rows x 84 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge the datasets on 'Customer ID' with suffixes to handle duplicate columns\n",
    "df_telcocustomerchurn = pd.merge(df_demographics, df_location, on='Customer ID', how='outer', suffixes=('_demographics', '_location'))\n",
    "df_telcocustomerchurn = pd.merge(df_telcocustomerchurn, df_services, on='Customer ID', how='outer', suffixes=('', '_services'))\n",
    "df_telcocustomerchurn = pd.merge(df_telcocustomerchurn, df_status, on='Customer ID', how='outer', suffixes=('', '_status'))\n",
    "df_telcocustomerchurn = pd.merge(df_telcocustomerchurn, df_customerc, on='Customer ID', how='outer', suffixes=('', '_customerc'))\n",
    "\n",
    "# Save the combined dataframe to a CSV file\n",
    "df_telcocustomerchurn.to_csv('../2_data/telcocustomerchurn.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the combined dataframe\n",
    "print(df_telcocustomerchurn.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 Customer ID  Count  Gender  Age Under 30 Senior Citizen Married  \\\n",
      "0        4006  0002-ORFBO      1  Female   37       No             No     Yes   \n",
      "1        4788  0003-MKNFE      1    Male   46       No             No      No   \n",
      "2        1901  0004-TLHLJ      1    Male   50       No             No      No   \n",
      "3         395  0011-IGKFF      1    Male   78       No            Yes     Yes   \n",
      "4         368  0013-EXCHZ      1  Female   75       No            Yes     Yes   \n",
      "\n",
      "  Dependents  Number of Dependents  ...  CLTV   Churn Category  \\\n",
      "0         No                     0  ...  2205              NaN   \n",
      "1         No                     0  ...  5414              NaN   \n",
      "2         No                     0  ...  4479       Competitor   \n",
      "3         No                     0  ...  3714  Dissatisfaction   \n",
      "4         No                     0  ...  3464  Dissatisfaction   \n",
      "\n",
      "                    Churn Reason LoyaltyID  Partner Tenure  Device Protection  \\\n",
      "0                            NaN    200315      Yes      9                 No   \n",
      "1                            NaN    278817       No      9                 No   \n",
      "2  Competitor had better devices    192691       No      4                Yes   \n",
      "3        Product dissatisfaction    318845      Yes     13                Yes   \n",
      "4            Network reliability    508649      Yes      3                 No   \n",
      "\n",
      "   Tech Support Monthly Charges Churn  \n",
      "0           Yes            65.6    No  \n",
      "1            No            59.9    No  \n",
      "2            No            73.9   Yes  \n",
      "3            No            98.0   Yes  \n",
      "4           Yes            83.9   Yes  \n",
      "\n",
      "[5 rows x 63 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge the datasets on 'Customer ID' without suffixes, avoiding duplicate columns\n",
    "df_combined = df_demographics\n",
    "for df in [df_location, df_services, df_status, df_customerc]:\n",
    "    for column in df.columns:\n",
    "        if column != 'Customer ID' and column in df_combined.columns:\n",
    "            df = df.drop(columns=[column])\n",
    "    df_combined = df_combined.merge(df, on='Customer ID', how='outer')\n",
    "\n",
    "# Drop duplicate columns\n",
    "df_combined = df_combined.loc[:, ~df_combined.columns.duplicated()]\n",
    "\n",
    "# Save the combined dataframe to a CSV file\n",
    "df_combined.to_csv('../2_data/telcocustomerchurn_combined.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the combined dataframe\n",
    "print(df_combined.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of `df_combined` and `df_telcocustomerchurn`\n",
    "\n",
    "The `df_combined` dataset is created by merging the `df_demographics`, `df_location`, `df_services`, `df_status`, and `df_customerc` datasets, while the `df_telcocustomerchurn` dataset is created by merging the same datasets but with suffixes to handle duplicate columns.\n",
    "\n",
    "**Advantages of `df_combined` without duplicates:**\n",
    "1. **Simplified Structure**: By avoiding duplicate columns, `df_combined` has a cleaner and more straightforward structure, making it easier to analyze and interpret.\n",
    "2. **Reduced Redundancy**: Eliminating duplicate columns reduces redundancy, ensuring that each piece of information is represented only once.\n",
    "3. **Improved Data Quality**: A dataset without duplicates is less prone to inconsistencies and errors, leading to higher data quality.\n",
    "4. **Efficient Storage**: A dataset with fewer columns requires less storage space and can be processed more efficiently.\n",
    "5. **Enhanced Readability**: A dataset without duplicate columns is more readable and easier to work with, especially for data visualization and reporting.\n",
    "\n",
    "In summary, `df_combined` provides a more streamlined and efficient dataset for analysis, while `df_telcocustomerchurn` includes all columns with suffixes to handle duplicates, which may be useful for specific use cases where retaining all original columns is necessary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
