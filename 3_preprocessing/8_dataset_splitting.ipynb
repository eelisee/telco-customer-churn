{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Split the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Pipeline Overview\n",
    "\n",
    "This preprocessing pipeline outlines the steps necessary to prepare the Telco Customer Churn dataset for our modeling. Each step is designed to address specific aspects of data quality, transformation, and feature creation. We will cover each step in a separate jupyter notebook file.\n",
    "\n",
    "**Step 1: Data Loading**: Loading the datasets into the workspace, ensuring all necessary files are correctly imported for analysis. This includes the Kaggle dataset and the IBM datasets.\n",
    "\n",
    "**Step 2: Dataset Integration**: Combining relevant datasets into a single, unified dataset that will serve as the foundation for subsequent analysis.\n",
    "\n",
    "**Step 3: Handling Missing Values**: Identifying and addressing missing values in the dataset to ensure data integrity. This step ensures no significant gaps hinder the analysis.\n",
    "\n",
    "**Step 4: Data Type Conversion**: Converting data columns to appropriate data types to optimize memory usage and prepare for feature engineering. Ensure consistency across all columns.\n",
    "\n",
    "**Step 5: Data Exploration**: Perform initial exploratory data analysis (EDA) to understand the dataset's structure and characteristics, visualizing key features to gain insights into the data.\n",
    "\n",
    "**Step 6: Feature Engineering**: Creating new features from the existing data to enhance model performance and capture additional insights. This includes transformations and derived features.\n",
    "\n",
    "**Step 7: Outlier Detection**: Identifying and addressing outliers in the dataset to ensure they do not negatively impact the analysis or models.\n",
    "\n",
    "**Step 8: Dataset Splitting**: Splitting the dataset into training and testing subsets to prepare for model development and evaluation. This step ensures reproducibility and robust performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods to Split the Dataset\n",
    "\n",
    "When working with a dataset of 7034 entries, it is crucial to split the data into training and testing subsets to evaluate the models performance accurately. Here are some common methods to split the dataset:\n",
    "\n",
    "1. **Train-Test Split**:\n",
    "    - This is the most straightforward method where the dataset is divided into two parts: training and testing sets.\n",
    "    - Typically, 70-80% of the data is used for training, and the remaining 20-30% is used for testing.\n",
    "\n",
    "2. **Stratified Shuffle Split**:\n",
    "    - This method ensures that the training and testing sets have the same proportion of class labels as the original dataset.\n",
    "    - It is particularly useful for imbalanced datasets.\n",
    "\n",
    "3. **K-Fold Cross-Validation**:\n",
    "    - This method splits the dataset into `k` equal-sized folds. The model is trained on `k-1` folds and tested on the remaining fold.\n",
    "    - This process is repeated `k` times, with each fold used exactly once as the test set.\n",
    "\n",
    "4. **Stratified K-Fold Cross-Validation**:\n",
    "    - Similar to K-Fold Cross-Validation but ensures that each fold has the same proportion of class labels.\n",
    "\n",
    "Each of these methods has its advantages and can be chosen based on the specific requirements of the analysis and the characteristics of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedShuffleSplit(n_splits=5, random_state=7, test_size=0.2,\n",
      "            train_size=None)\n",
      "train: [4486 1855 3910 ... 4687  690 5658] test: [ 724  945 4710 ... 3730 1633 2496]\n",
      "train: [ 937 6833 3567 ... 4257 4716 5657] test: [6171  505 5903 ... 6911 2257 5571]\n",
      "train: [4793 2570 3406 ...  805 2103 1162] test: [  31 2128 2079 ... 2313 6356 5365]\n",
      "train: [6799  180 3061 ... 3155 2428  793] test: [3083 4441  980 ... 4552 2903 1479]\n",
      "train: [ 603 4034 6970 ... 1356 4927 1489] test: [5931 4868 2690 ... 3344 6206 5245]\n",
      "X shape: (7043, 116)\n",
      "X_train shape: (5634, 116)\n",
      "X_test shape: (1409, 116)\n",
      "y shape: (7043,)\n",
      "y_train shape: (5634,)\n",
      "y_test shape: (1409,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../2_data/telcocustomerchurn_featured.csv\")\n",
    "# Define the features and target variable\n",
    "X = df.drop(columns=['Churn'])\n",
    "y = df['Churn']\n",
    "\n",
    "# StratifiedShuffleSplit \n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=7)\n",
    "print(sss)\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"train:\", train_index, \"test:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Save the train and test splits to CSV files\n",
    "X_train.to_csv(\"../2_data/X_train.csv\", index=False)\n",
    "X_test.to_csv(\"../2_data/X_test.csv\", index=False)\n",
    "y_train.to_csv(\"../2_data/y_train.csv\", index=False)\n",
    "y_test.to_csv(\"../2_data/y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'Count', 'Gender', 'Age', 'Under 30', 'Senior Citizen', 'Married', 'Dependents', 'Number of Dependents', 'City', 'Zip Code', 'Latitude', 'Longitude', 'Referred a Friend', 'Number of Referrals', 'Tenure in Months', 'Phone Service', 'Avg Monthly Long Distance Charges', 'Multiple Lines', 'Internet Service', 'Avg Monthly GB Download', 'Online Security', 'Online Backup', 'Device Protection Plan', 'Premium Tech Support', 'Streaming TV', 'Streaming Movies', 'Streaming Music', 'Unlimited Data', 'Paperless Billing', 'Monthly Charge', 'Total Charges', 'Total Refunds', 'Total Extra Data Charges', 'Total Long Distance Charges', 'Total Revenue', 'Satisfaction Score', 'Churn Value', 'Churn Score', 'CLTV', 'LoyaltyID', 'Partner', 'Tenure', 'Monthly Charges', 'Country_United States', 'State_California', 'Quarter_Q3', 'Offer_Offer A', 'Offer_Offer B', 'Offer_Offer C', 'Offer_Offer D', 'Offer_Offer E', 'Internet Type_Cable', 'Internet Type_DSL', 'Internet Type_Fiber Optic', 'Contract_Month-to-Month', 'Contract_One Year', 'Contract_Two Year', 'Payment Method_Bank Withdrawal', 'Payment Method_Credit Card', 'Payment Method_Mailed Check', 'Customer Status_Churned', 'Customer Status_Joined', 'Customer Status_Stayed', 'Churn Category_Attitude', 'Churn Category_Competitor', 'Churn Category_Dissatisfaction', 'Churn Category_Other', 'Churn Category_Price', 'Churn Reason_Attitude of service provider', 'Churn Reason_Attitude of support person', 'Churn Reason_Competitor had better devices', 'Churn Reason_Competitor made better offer', 'Churn Reason_Competitor offered higher download speeds', 'Churn Reason_Competitor offered more data', 'Churn Reason_Deceased', \"Churn Reason_Don't know\", 'Churn Reason_Extra data charges', 'Churn Reason_Lack of affordable download/upload speed', 'Churn Reason_Lack of self-service on Website', 'Churn Reason_Limited range of services', 'Churn Reason_Long distance charges', 'Churn Reason_Moved', 'Churn Reason_Network reliability', 'Churn Reason_Poor expertise of online support', 'Churn Reason_Poor expertise of phone support', 'Churn Reason_Price too high', 'Churn Reason_Product dissatisfaction', 'Churn Reason_Service dissatisfaction', 'Device Protection_No', 'Device Protection_No internet service', 'Device Protection_Yes', 'Tech Support_No', 'Tech Support_No internet service', 'Tech Support_Yes', 'Lat', 'Long', 'SeniorCitizen_Dependents', 'Tenure_Age_Ratio', 'AvgMonthlyGB_StreamServices', 'MonthlyCharge_TotalCharges_Ratio', 'ChurnScore_CLTV', 'AvgMonthlyGB_Tenure', 'Total_Services_Used', 'Streaming_Services_Count', 'Internet_Phone_Bundle', 'Tenure_in_Years', 'Digital_Payments', 'Traditional_Payments', 'Monthly_Charges_Scaled', 'Revenue_Cluster_Low', 'Revenue_Cluster_Medium', 'Revenue_Cluster_High', 'Refund_to_Charges_Ratio', 'Extra_Data_Usage_Cost_Proportion', 'Lifetime_Value_per_Month']\n"
     ]
    }
   ],
   "source": [
    "# Print the columns of the dataframe\n",
    "print(X_train.columns.tolist())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
