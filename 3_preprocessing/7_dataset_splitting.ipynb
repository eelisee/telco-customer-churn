{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Split the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Pipeline Overview\n",
    "\n",
    "This preprocessing pipeline outlines the steps necessary to prepare the Telco Customer Churn dataset for our modeling. Each step is designed to address specific aspects of data quality, transformation, and feature creation. We will cover each step in a separate jupyter notebook file.\n",
    "\n",
    "**Step 1: Data Loading**: Loading the datasets into the workspace, ensuring all necessary files are correctly imported for analysis. This includes the Kaggle dataset and the IBM datasets.\n",
    "\n",
    "**Step 2: Dataset Integration**: Combining relevant datasets into a single, unified dataset that will serve as the foundation for subsequent analysis.\n",
    "\n",
    "**Step 3: Handling Missing Values**: Identifying and addressing missing values in the dataset to ensure data integrity. This step ensures no significant gaps hinder the analysis.\n",
    "\n",
    "**Step 4: Data Type Conversion**: Converting data columns to appropriate data types to optimize memory usage and prepare for feature engineering. Ensure consistency across all columns.\n",
    "\n",
    "**Step 5: Data Exploration**: Perform initial exploratory data analysis (EDA) to understand the dataset's structure and characteristics, visualizing key features to gain insights into the data.\n",
    "\n",
    "**Step 6: Feature Engineering**: Creating new features from the existing data to enhance model performance and capture additional insights. This includes transformations and derived features.\n",
    "\n",
    "**Step 7: Dataset Splitting**: Splitting the dataset into training and testing subsets to prepare for model development and evaluation. This step ensures reproducibility and robust performance metrics.\n",
    "\n",
    "**Step 8: Outlier Detection**: Identifying and addressing outliers in the dataset to ensure they do not negatively impact the analysis or models.\n",
    "\n",
    "**Step 9: Clustering Customers**: Identifying the most common customer profiles via clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods to Split the Dataset\n",
    "\n",
    "When working with a dataset of 7034 entries, it is crucial to split the data into training and testing subsets to evaluate the models performance accurately. Here are some common methods to split the dataset:\n",
    "\n",
    "1. **Train-Test Split**:\n",
    "    - This is the most straightforward method where the dataset is divided into two parts: training and testing sets.\n",
    "    - Typically, 70-80% of the data is used for training, and the remaining 20-30% is used for testing.\n",
    "\n",
    "2. **Stratified Shuffle Split**:\n",
    "    - This method ensures that the training and testing sets have the same proportion of class labels as the original dataset.\n",
    "    - It is particularly useful for imbalanced datasets.\n",
    "\n",
    "3. **K-Fold Cross-Validation**:\n",
    "    - This method splits the dataset into `k` equal-sized folds. The model is trained on `k-1` folds and tested on the remaining fold.\n",
    "    - This process is repeated `k` times, with each fold used exactly once as the test set.\n",
    "\n",
    "4. **Stratified K-Fold Cross-Validation**:\n",
    "    - Similar to K-Fold Cross-Validation but ensures that each fold has the same proportion of class labels.\n",
    "\n",
    "Each of these methods has its advantages and can be chosen based on the specific requirements of the analysis and the characteristics of the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to drop the 'Churn', 'Customer Status_Churned', and 'Churn Value' columns from the dataset.\n",
    "The last two columns are encodings of the 'Churn' column, so all three columns are removed to avoid redundancy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'Count', 'Gender', 'Age', 'Under 30', 'Senior Citizen', 'Married', 'Dependents', 'Number of Dependents', 'City', 'Zip Code', 'Latitude', 'Longitude', 'Referred a Friend', 'Number of Referrals', 'Tenure in Months', 'Phone Service', 'Avg Monthly Long Distance Charges', 'Multiple Lines', 'Internet Service', 'Avg Monthly GB Download', 'Online Security', 'Online Backup', 'Device Protection Plan', 'Premium Tech Support', 'Streaming TV', 'Streaming Movies', 'Streaming Music', 'Unlimited Data', 'Paperless Billing', 'Monthly Charge', 'Total Charges', 'Total Refunds', 'Total Extra Data Charges', 'Total Long Distance Charges', 'Total Revenue', 'Satisfaction Score', 'Churn Value', 'Churn Score', 'CLTV', 'LoyaltyID', 'Partner', 'Tenure', 'Monthly Charges', 'Churn', 'Country_United States', 'State_California', 'Quarter_Q3', 'Offer_Offer A', 'Offer_Offer B', 'Offer_Offer C', 'Offer_Offer D', 'Offer_Offer E', 'Internet Type_Cable', 'Internet Type_DSL', 'Internet Type_Fiber Optic', 'Contract_Month-to-Month', 'Contract_One Year', 'Contract_Two Year', 'Payment Method_Bank Withdrawal', 'Payment Method_Credit Card', 'Payment Method_Mailed Check', 'Customer Status_Churned', 'Customer Status_Joined', 'Customer Status_Stayed', 'Churn Category_Attitude', 'Churn Category_Competitor', 'Churn Category_Dissatisfaction', 'Churn Category_Other', 'Churn Category_Price', 'Churn Reason_Attitude of service provider', 'Churn Reason_Attitude of support person', 'Churn Reason_Competitor had better devices', 'Churn Reason_Competitor made better offer', 'Churn Reason_Competitor offered higher download speeds', 'Churn Reason_Competitor offered more data', 'Churn Reason_Deceased', \"Churn Reason_Don't know\", 'Churn Reason_Extra data charges', 'Churn Reason_Lack of affordable download/upload speed', 'Churn Reason_Lack of self-service on Website', 'Churn Reason_Limited range of services', 'Churn Reason_Long distance charges', 'Churn Reason_Moved', 'Churn Reason_Network reliability', 'Churn Reason_Poor expertise of online support', 'Churn Reason_Poor expertise of phone support', 'Churn Reason_Price too high', 'Churn Reason_Product dissatisfaction', 'Churn Reason_Service dissatisfaction', 'Device Protection_No', 'Device Protection_No internet service', 'Device Protection_Yes', 'Tech Support_No', 'Tech Support_No internet service', 'Tech Support_Yes', 'Lat', 'Long', 'SeniorCitizen_Dependents', 'Tenure_Age_Ratio', 'AvgMonthlyGB_StreamServices', 'MonthlyCharge_TotalCharges_Ratio', 'AvgMonthlyGB_Tenure', 'Total_Services_Used', 'Streaming_Services_Count', 'Internet_Phone_Bundle', 'Tenure_in_Years', 'Digital_Payments', 'Traditional_Payments', 'Monthly_Charges_Scaled', 'Revenue_Cluster_Low', 'Revenue_Cluster_Medium', 'Revenue_Cluster_High', 'Refund_to_Charges_Ratio', 'Extra_Data_Usage_Cost_Proportion', 'Lifetime_Value_per_Month', 'Monthly_Charges_18.25-35.5', 'Monthly_Charges_35.51-70.35', 'Monthly_Charges_70.36-89.85', 'Monthly_Charges_89.86-118.75', 'Lifetime_Value_43-85.918', 'Lifetime_Value_85.919-137.263', 'Lifetime_Value_137.264-460.95', 'Lifetime_Value_460.951-5996']\n",
      "Unnamed: 0                       int64\n",
      "Count                            int64\n",
      "Gender                           int64\n",
      "Age                              int64\n",
      "Under 30                         int64\n",
      "                                 ...  \n",
      "Monthly_Charges_89.86-118.75     int64\n",
      "Lifetime_Value_43-85.918         int64\n",
      "Lifetime_Value_85.919-137.263    int64\n",
      "Lifetime_Value_137.264-460.95    int64\n",
      "Lifetime_Value_460.951-5996      int64\n",
      "Length: 124, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../2_data/telcocustomerchurn_featured.csv\")\n",
    "print(df.columns.tolist())\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting Columns encoding information about Churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We delete all columns that include \"churn\" in their name because these features are highly likely to introduce data leakage. \n",
    "Data leakage occurs when information from outside the training dataset is used to create the model, leading to overly optimistic performance estimates. \n",
    "In this case, columns such as 'Churn Value', 'Churn Score', 'Churn', 'Customer Status_Churned', and various 'Churn Category' and 'Churn Reason' columns \n",
    "are either explicitly tied to the target variable (churn) or derived from it. Including these columns in the model would provide it with information \n",
    "that would not be available in a real-world scenario, thus compromising the model's ability to generalize to new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Churn Value', 'Churn Score', 'Churn', 'Customer Status_Churned', 'Churn Category_Attitude', 'Churn Category_Competitor', 'Churn Category_Dissatisfaction', 'Churn Category_Other', 'Churn Category_Price', 'Churn Reason_Attitude of service provider', 'Churn Reason_Attitude of support person', 'Churn Reason_Competitor had better devices', 'Churn Reason_Competitor made better offer', 'Churn Reason_Competitor offered higher download speeds', 'Churn Reason_Competitor offered more data', 'Churn Reason_Deceased', \"Churn Reason_Don't know\", 'Churn Reason_Extra data charges', 'Churn Reason_Lack of affordable download/upload speed', 'Churn Reason_Lack of self-service on Website', 'Churn Reason_Limited range of services', 'Churn Reason_Long distance charges', 'Churn Reason_Moved', 'Churn Reason_Network reliability', 'Churn Reason_Poor expertise of online support', 'Churn Reason_Poor expertise of phone support', 'Churn Reason_Price too high', 'Churn Reason_Product dissatisfaction', 'Churn Reason_Service dissatisfaction']\n"
     ]
    }
   ],
   "source": [
    "churn_columns = [col for col in df.columns if 'Churn' in col]\n",
    "print(churn_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'Count', 'Gender', 'Age', 'Under 30', 'Senior Citizen', 'Married', 'Dependents', 'Number of Dependents', 'City', 'Zip Code', 'Latitude', 'Longitude', 'Referred a Friend', 'Number of Referrals', 'Tenure in Months', 'Phone Service', 'Avg Monthly Long Distance Charges', 'Multiple Lines', 'Internet Service', 'Avg Monthly GB Download', 'Online Security', 'Online Backup', 'Device Protection Plan', 'Premium Tech Support', 'Streaming TV', 'Streaming Movies', 'Streaming Music', 'Unlimited Data', 'Paperless Billing', 'Monthly Charge', 'Total Charges', 'Total Refunds', 'Total Extra Data Charges', 'Total Long Distance Charges', 'Total Revenue', 'Satisfaction Score', 'CLTV', 'LoyaltyID', 'Partner', 'Tenure', 'Monthly Charges', 'Churn', 'Country_United States', 'State_California', 'Quarter_Q3', 'Offer_Offer A', 'Offer_Offer B', 'Offer_Offer C', 'Offer_Offer D', 'Offer_Offer E', 'Internet Type_Cable', 'Internet Type_DSL', 'Internet Type_Fiber Optic', 'Contract_Month-to-Month', 'Contract_One Year', 'Contract_Two Year', 'Payment Method_Bank Withdrawal', 'Payment Method_Credit Card', 'Payment Method_Mailed Check', 'Customer Status_Joined', 'Customer Status_Stayed', 'Device Protection_No', 'Device Protection_No internet service', 'Device Protection_Yes', 'Tech Support_No', 'Tech Support_No internet service', 'Tech Support_Yes', 'Lat', 'Long', 'SeniorCitizen_Dependents', 'Tenure_Age_Ratio', 'AvgMonthlyGB_StreamServices', 'MonthlyCharge_TotalCharges_Ratio', 'AvgMonthlyGB_Tenure', 'Total_Services_Used', 'Streaming_Services_Count', 'Internet_Phone_Bundle', 'Tenure_in_Years', 'Digital_Payments', 'Traditional_Payments', 'Monthly_Charges_Scaled', 'Revenue_Cluster_Low', 'Revenue_Cluster_Medium', 'Revenue_Cluster_High', 'Refund_to_Charges_Ratio', 'Extra_Data_Usage_Cost_Proportion', 'Lifetime_Value_per_Month', 'Monthly_Charges_18.25-35.5', 'Monthly_Charges_35.51-70.35', 'Monthly_Charges_70.36-89.85', 'Monthly_Charges_89.86-118.75', 'Lifetime_Value_43-85.918', 'Lifetime_Value_85.919-137.263', 'Lifetime_Value_137.264-460.95', 'Lifetime_Value_460.951-5996']\n"
     ]
    }
   ],
   "source": [
    "# Drop all columns containing \"Churn\" in their name except the \"Churn\" column\n",
    "churn_columns_to_drop = [col for col in churn_columns if col != 'Churn']\n",
    "df = df.drop(columns=churn_columns_to_drop)\n",
    "\n",
    "# Display the remaining columns\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop the `unnamed_0` column, which is an additional unique identifier that was added and is not needed. Furthermore, we will drop the `Customer Status` columns, since they encode the Churn as well. Furthermore, since the 'LoyaltyID' is a numerical value encoding the Customer Loyalty (not churning), we will delete this as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedShuffleSplit(n_splits=5, random_state=7, test_size=0.2,\n",
      "            train_size=None)\n",
      "train: [4486 1855 3910 ... 4687  690 5658] test: [ 724  945 4710 ... 3730 1633 2496]\n",
      "train: [ 937 6833 3567 ... 4257 4716 5657] test: [6171  505 5903 ... 6911 2257 5571]\n",
      "train: [4793 2570 3406 ...  805 2103 1162] test: [  31 2128 2079 ... 2313 6356 5365]\n",
      "train: [6799  180 3061 ... 3155 2428  793] test: [3083 4441  980 ... 4552 2903 1479]\n",
      "train: [ 603 4034 6970 ... 1356 4927 1489] test: [5931 4868 2690 ... 3344 6206 5245]\n",
      "X shape: (7043, 93)\n",
      "X_train shape: (5634, 93)\n",
      "X_test shape: (1409, 93)\n",
      "y shape: (7043,)\n",
      "y_train shape: (5634,)\n",
      "y_test shape: (1409,)\n"
     ]
    }
   ],
   "source": [
    "# Define the features and target variable\n",
    "X = df.drop(columns=['Customer Status_Joined', 'Customer Status_Stayed', 'LoyaltyID'])\n",
    "y = df['Churn']\n",
    "\n",
    "# StratifiedShuffleSplit \n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=7)\n",
    "print(sss)\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"train:\", train_index, \"test:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    X_train_dashboard, X_test_dashboard = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    y_train_dashboard, y_test_dashboard = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Add 'Unnamed: 0' column to y_train_dashboard and y_test_dashboard\n",
    "    y_train_dashboard = pd.DataFrame(y_train_dashboard).merge(X_train_dashboard[['Unnamed: 0']], left_index=True, right_index=True)\n",
    "    y_test_dashboard = pd.DataFrame(y_test_dashboard).merge(X_test_dashboard[['Unnamed: 0']], left_index=True, right_index=True)\n",
    "\n",
    "    # Ensure the order of rows in X_train and X_test corresponds to y_train and y_test\n",
    "    \n",
    "\n",
    "    # Sort the train and test sets to keep the order the same\n",
    "    X_train = X_train.sort_index()\n",
    "    X_test = X_test.sort_index()\n",
    "    X_train_dashboard = X_train_dashboard.sort_index()\n",
    "    X_test_dashboard = X_test_dashboard.sort_index()\n",
    "    y_train = y_train.sort_index()\n",
    "    y_test = y_test.sort_index()\n",
    "    y_train_dashboard = y_train_dashboard.sort_index()\n",
    "    y_test_dashboard = y_test_dashboard.sort_index()\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Save the train and test splits to CSV files\n",
    "X_train.to_csv(\"../2_data/X_train.csv\", index=False)\n",
    "X_test.to_csv(\"../2_data/X_test.csv\", index=False)\n",
    "X_train_dashboard.to_csv(\"../2_data/X_train_dashboard.csv\", index=False)\n",
    "X_test_dashboard.to_csv(\"../2_data/X_test_dashboard.csv\", index=False)\n",
    "y_train.to_csv(\"../2_data/y_train.csv\", index=False)\n",
    "y_test.to_csv(\"../2_data/y_test.csv\", index=False)\n",
    "y_train_dashboard.to_csv(\"../2_data/y_train_dashboard.csv\", index=False)\n",
    "y_test_dashboard.to_csv(\"../2_data/y_test_dashboard.csv\", index=False)\n",
    "\n",
    "# Drop the specified columns from X_train and X_test\n",
    "X_train = X_train.drop(columns=['Churn', 'Unnamed: 0'])\n",
    "X_test = X_test.drop(columns=['Churn', 'Unnamed: 0'])\n",
    "y_train = y_train.drop(columns=['Unnamed: 0'])\n",
    "y_test = y_test.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Save the modified train and test splits to CSV files\n",
    "X_train.to_csv(\"../2_data/X_train.csv\", index=False)\n",
    "X_test.to_csv(\"../2_data/X_test.csv\", index=False)\n",
    "y_train.to_csv(\"../2_data/y_train.csv\", index=False)\n",
    "y_test.to_csv(\"../2_data/y_test.csv\", index=False)\n",
    "\n",
    "# Load the combined dataset to get the Customer ID\n",
    "combined_df = pd.read_csv(\"../2_data/telcocustomerchurn_combined.csv\")\n",
    "\n",
    "# Merge the Customer ID into X_train_dashboard and X_test_dashboard based on the \"Unnamed: 0\" column\n",
    "X_train_dashboard = X_train_dashboard.merge(combined_df[['Unnamed: 0', 'Customer ID']], on='Unnamed: 0')\n",
    "X_test_dashboard = X_test_dashboard.merge(combined_df[['Unnamed: 0', 'Customer ID']], on='Unnamed: 0')\n",
    "y_train_dashboard = pd.DataFrame(y_train_dashboard).merge(combined_df[['Unnamed: 0', 'Customer ID']], on='Unnamed: 0')\n",
    "y_test_dashboard = pd.DataFrame(y_test_dashboard).merge(combined_df[['Unnamed: 0', 'Customer ID']], on='Unnamed: 0')\n",
    "\n",
    "X_train_dashboard = X_train_dashboard.drop(columns=['Unnamed: 0', 'Churn'])\n",
    "X_test_dashboard = X_test_dashboard.drop(columns=['Unnamed: 0', 'Churn'])\n",
    "y_train_dashboard = y_train_dashboard.drop(columns=['Unnamed: 0'])\n",
    "y_test_dashboard = y_test_dashboard.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "\n",
    "# Drop any rows that have an NaN in them for X_train_dashboard, X_test_dashboard, y_train_dashboard, and y_test_dashboard\n",
    "X_train_dashboard = X_train_dashboard.dropna()\n",
    "X_test_dashboard = X_test_dashboard.dropna()\n",
    "y_train_dashboard = y_train_dashboard.dropna()\n",
    "y_test_dashboard = y_test_dashboard.dropna()\n",
    "\n",
    "\n",
    "\n",
    "# Save the updated train and test dashboard splits to CSV files\n",
    "X_train_dashboard.to_csv(\"../2_data/X_train_dashboard.csv\", index=False)\n",
    "X_test_dashboard.to_csv(\"../2_data/X_test_dashboard.csv\", index=False)\n",
    "y_train_dashboard.to_csv(\"../2_data/y_train_dashboard.csv\", index=False)\n",
    "y_test_dashboard.to_csv(\"../2_data/y_test_dashboard.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Count', 'Gender', 'Age', 'Under 30', 'Senior Citizen', 'Married', 'Dependents', 'Number of Dependents', 'City', 'Zip Code', 'Latitude', 'Longitude', 'Referred a Friend', 'Number of Referrals', 'Tenure in Months', 'Phone Service', 'Avg Monthly Long Distance Charges', 'Multiple Lines', 'Internet Service', 'Avg Monthly GB Download', 'Online Security', 'Online Backup', 'Device Protection Plan', 'Premium Tech Support', 'Streaming TV', 'Streaming Movies', 'Streaming Music', 'Unlimited Data', 'Paperless Billing', 'Monthly Charge', 'Total Charges', 'Total Refunds', 'Total Extra Data Charges', 'Total Long Distance Charges', 'Total Revenue', 'Satisfaction Score', 'CLTV', 'Partner', 'Tenure', 'Monthly Charges', 'Country_United States', 'State_California', 'Quarter_Q3', 'Offer_Offer A', 'Offer_Offer B', 'Offer_Offer C', 'Offer_Offer D', 'Offer_Offer E', 'Internet Type_Cable', 'Internet Type_DSL', 'Internet Type_Fiber Optic', 'Contract_Month-to-Month', 'Contract_One Year', 'Contract_Two Year', 'Payment Method_Bank Withdrawal', 'Payment Method_Credit Card', 'Payment Method_Mailed Check', 'Device Protection_No', 'Device Protection_No internet service', 'Device Protection_Yes', 'Tech Support_No', 'Tech Support_No internet service', 'Tech Support_Yes', 'Lat', 'Long', 'SeniorCitizen_Dependents', 'Tenure_Age_Ratio', 'AvgMonthlyGB_StreamServices', 'MonthlyCharge_TotalCharges_Ratio', 'AvgMonthlyGB_Tenure', 'Total_Services_Used', 'Streaming_Services_Count', 'Internet_Phone_Bundle', 'Tenure_in_Years', 'Digital_Payments', 'Traditional_Payments', 'Monthly_Charges_Scaled', 'Revenue_Cluster_Low', 'Revenue_Cluster_Medium', 'Revenue_Cluster_High', 'Refund_to_Charges_Ratio', 'Extra_Data_Usage_Cost_Proportion', 'Lifetime_Value_per_Month', 'Monthly_Charges_18.25-35.5', 'Monthly_Charges_35.51-70.35', 'Monthly_Charges_70.36-89.85', 'Monthly_Charges_89.86-118.75', 'Lifetime_Value_43-85.918', 'Lifetime_Value_85.919-137.263', 'Lifetime_Value_137.264-460.95', 'Lifetime_Value_460.951-5996']\n"
     ]
    }
   ],
   "source": [
    "# Print the columns of the dataframe\n",
    "print(X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Cross-Validation Function\n",
    "\n",
    "By defining a cross-validation function, we can streamline the process of evaluating different models and methods, ensuring reproducibility and consistency in your results. This function can be applied to various machine learning algorithms and dataset splits, allowing you to assess their performance using the same cross-validation strategy.\n",
    "We will refer to the cross validation in each method evaluation section."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
